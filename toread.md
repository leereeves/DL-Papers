# Reading list

Diagnosing Bottlenecks in Deep Q-learning Algorithms

A Theoretical Analysis of Deep Q-Learning

Deep Q-learning: a robust control approach

Towards Characterizing Divergence in Deep Q-Learning

Adaptive Rational Activations to Boost Deep Reinforcement Learning

StarCraft II: A New Challenge for Reinforcement Learning

Multimodal deep learning models for early detection of Alzheimerâ€™s disease stage

From data to functa: Your data point is a function and you can treat it like one          
THE COST OF TRAINING NLP MODELS A CONCISE OVERVIEW

Decoupled Weight Decay Regularization

Continual lifelong learning with neural networks: A review

Experience Replay for Continual Learning

Boltzmann Exploration Done Right

Propositions Concerning Digital Minds and Society

Diffusion probabilistic modeling of protein backbones in 3D for the motif-scaffolding problem

Explicit Regularization in Overparametrized Models via Noise Injection

Beyond the Imitation Game benchmark (BIG-bench)

Why Agent Foundations? An Overly Abstract Explanation

Learning to Generate Artistic Character Line Drawing

Diffusion-LM Improves Controllable Text Generation

The dopamine circuit as a reward-taxis navigation system

Multi-Game Decision Transformers

Rule-based Information Extraction is Dead!
Long Live Rule-based Information Extraction Systems!

Language Models are Few-Shot Learners

A survey on recently proposed activation functions for Deep Learning

REINFORCEMENT LEARNING IN CONTINUOUS TIME:
ADVANTAGE UPDATING

Massively Parallel Methods for Deep Reinforcement Learning

Hindsight Experience Replay

CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING

Deep Reinforcement Learning and the Deadly Triad

Safe and Nested Subgame Solving for Imperfect-Information Games

Delving Deep into Rectifiers:
Surpassing Human-Level Performance on ImageNet Classification

Constrained Deep Q-Learning Gradually Approaching Ordinary Q-Learning

MEMORIZING TRANSFORMERS

An Intuitive Introduction to Deep Autoregressive Networks By McClain Thiel

Auto-Encoding Variational Bayes

beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework

Generating Diverse High-Fidelity Images with VQ-VAE-2

Cyclical Annealing Schedule: A Simple Approach to Mitigating KL Vanishing

Gotta Learn Fast: A New Benchmark for Generalization in RL

How Neural Networks Extrapolate: From Feedforward to Graph Neural Networks

ZeRO: Memory Optimizations Toward Training Trillion Parameter Models

GPT-3: Language Models are Few-Shot Learners

REINFORCEMENT LEARNING IN CONTINUOUS TIME: ADVANTAGE UPDATING

Offline Reinforcement Learning as One Big Sequence Modeling Problem

Massively Parallel Methods for Deep Reinforcement Learning

Hindsight Experience Replay

CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING

Explicit Regularization in Overparametrized Models via Noise Injection

Large-Scale Retrieval for Reinforcement Learning

CTRL: A CONDITIONAL TRANSFORMER LANGUAGE MODEL FOR CONTROLLABLE GENERATION

Reinforcement Learning with Non-Markovian Rewards

Variational inference & deep learning A new synthesis Kingma, D.P.
https://pure.uva.nl/ws/files/17891313/Thesis.pdf

Groupoids: Unifying Internal and External Symmetry

A Metric Learning Reality Check

Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift

Neural network with unbounded activation functions is universal approximator

State of the Art Control of Atari Games Using Shallow Reinforcement Learning

Efficient BackProp, LeCun et al

Interpretation and Generalization of Score Matching

Contrastive Learning as Goal-Conditioned Reinforcement Learning

Prioritized Training on Points that are Learnable, Worth Learning, and Not Yet Learnt

Decentralized Training of Foundation Models in Heterogeneous Environments

Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks

PARAMETER SPACE NOISE FOR EXPLORATION

Convergence Proof for Actor-Critic Methods Applied to PPO and RUDDER

Deep Deterministic Policy Gradient Based on Double Network Prioritized Experience Replay

Revisiting the Softmax Bellman Operator: Theoretical Properties and Practical Benefits

Learning values across many orders of magnitude

